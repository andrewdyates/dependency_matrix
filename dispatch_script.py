#!/usr/bin/python
"""Dispatch parallel job to compute dependency matrix.

EXAMPLE USE:
python $HOME/recomb2013_workbench/dependency_matrix/dispatch_script.py fname1=/fs/lustre/osu6683/recomb2013_gse15745/GSE15745_GPL6104.data.aligned.pkl fname2=/fs/lustre/osu6683/recomb2013_gse15745/GSE15745_GPL8490.data.aligned.pkl computers=[\"Dcor\",\"PCC\"] outdir=/fs/lustre/osu6683/recomb2013_gse15745/dispatch_test dry=True
"""
import datetime
import random
from __init__ import *
from matrix_io import *
from qsub import *
import json
import shutil
import sys


bname = os.path.basename
K = 100000
def load_cp_and_make_bin(fname, outdir):
  d = load(fname)
  M, ftype = d["M"], d["ftype"]
  if ftype != "pkl":
    fname_new = os.path.join(outdir, bname(fname.rpartition('.')[0])+".pkl")
    save(M, fname_new)
    print "Saved binary copy of matrix %s as %s" % (fname, fname_new)
  else:
    fname_new = os.path.join(outdir, bname(fname))
    if os.path.abspath(fname) != os.path.abspath(fname_new) and not os.path.exists(fname_new):
      print "Matrix is not in out directory %s. Copying to %s" % (outdir, fname_new)
      shutil.copy(fname, fname_new)
  return (M, fname_new)


def main(fname=None, fname1=None, fname2=None, computers=None, outdir=None, n_nodes=1, n_ppn=1, hours=8, compute_options=None, dry=False):

  assert bool(fname) != bool(fname1 and fname2)
  if computers is None:
    computers = COMPUTERS.keys()
  else:
    if isinstance(computers, basestring):
      computers = json.loads(computers)
    assert not set(computers) - set(COMPUTERS.keys())
  if not os.path.exists(outdir):
    make_dir(outdir)
    print "Created outdir %s" % outdir
  assert n_nodes >= 1
  assert n_ppn >= 1 and n_ppn <= 12
  assert hours >= 1 and hours <= 99
  os.chdir(outdir)
  compiled_dir = os.path.join(outdir, "compiled")

  if fname:
    mtype = "self"
    assert os.path.exists(fname)
    M, fname_work = load_cp_and_make_bin(fname, outdir)
  else:
    mtype = "dual"
    assert os.path.exists(fname1) and os.path.exists(fname2)
    M1, fname_work1 = load_cp_and_make_bin(fname1, outdir)
    M2, fname_work2 = load_cp_and_make_bin(fname2, outdir)

  pids = []
  for comp_name in computers:
    comp_dir = os.path.join(outdir, comp_name)
    
    if mtype == "self":
      jobname = "%s_%s" % (comp_name, bname(fname_work))
      Q = Qsub(jobname=jobname, n_nodes=n_nodes, n_ppn=n_ppn, hours=hours, work_dir=outdir)
      # Generate list of batch_script.py executions to divide work.
      cmds = shells_dispatch_self(fname_work, np.size(M,0), comp_name, compute_options, k=K)
      Q.add_parallel(cmds)
      # compile_script.py compiles matrices generated by batch_script.py by file path
        # (filename RX patterns in batch_script.py)
      
    elif mtype == "dual":
      jobname = "%s_%s_%s" % (comp_name, bname(fname_work1), bname(fname_work2))
      Q = Qsub(jobname=jobname, n_nodes=n_nodes, n_ppn=n_ppn, hours=hours, work_dir=outdir)
      cmds = shells_dispatch_dual(fname_work1, fname_work2, np.size(M2,0), comp_name, compute_options)
      Q.add_parallel(cmds)

    cmd = shell_compile(compiled_dir, comp_dir, mtype)
    Q.add(cmd)
    pid = Q.submit(dry)
    print Q.script()
    print "Submitted dispatch, job ID: %s" % pid
    pids.append(pid)

  # After all jobs have completed, compile .json job and send email on completion.
  Q = Qsub(jobname="%s_JSONCompile"%fname, work_dir=outdir, email=True, after_jobids=pids)
  Q.add(shell_jsonindex(compiled_dir, comp_dir, mtype))
  print Q.script()
  pid = Q.submit(dry)
  print "Final PID: %s" % pid
  return pid


if __name__ == "__main__":
  kwds = dict([s.split('=') for s in sys.argv[1:]])
  print kwds
  main(**kwds)
